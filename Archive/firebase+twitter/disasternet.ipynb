{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "disasternet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx8qX_LcA-aO",
        "colab_type": "code",
        "outputId": "ccfd0370-7fc9-41e0-f9f5-abb576afa825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "!pip3 install --quiet seaborn\n",
        "!wget https://raw.githubusercontent.com/sajao/CrisisLex/master/releases/CrisisLexT26-v1.0.zip\n",
        "!unzip CrisisLexT26-v1.0.zip\n",
        "!pip install --quiet langdetect"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-15 06:46:25--  https://raw.githubusercontent.com/sajao/CrisisLex/master/releases/CrisisLexT26-v1.0.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4758309 (4.5M) [application/zip]\n",
            "Saving to: ‘CrisisLexT26-v1.0.zip.2’\n",
            "\n",
            "CrisisLexT26-v1.0.z 100%[===================>]   4.54M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-09-15 06:46:26 (39.2 MB/s) - ‘CrisisLexT26-v1.0.zip.2’ saved [4758309/4758309]\n",
            "\n",
            "Archive:  CrisisLexT26-v1.0.zip\n",
            "replace CrisisLexT26/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: CrisisLexT26/.DS_Store  \n",
            "  inflating: __MACOSX/CrisisLexT26/._.DS_Store  \n",
            "  inflating: CrisisLexT26/2012_Colorado_wildfires/2012_Colorado_wildfires-event_description.json  \n",
            "  inflating: CrisisLexT26/2012_Colorado_wildfires/2012_Colorado_wildfires-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2012_Colorado_wildfires/2012_Colorado_wildfires-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2012_Colorado_wildfires/README.md  \n",
            "  inflating: CrisisLexT26/2012_Costa_Rica_earthquake/2012_Costa_Rica_earthquake-event_description.json  \n",
            "  inflating: CrisisLexT26/2012_Costa_Rica_earthquake/2012_Costa_Rica_earthquake-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2012_Costa_Rica_earthquake/2012_Costa_Rica_earthquake-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2012_Costa_Rica_earthquake/README.md  \n",
            "  inflating: CrisisLexT26/2012_Guatemala_earthquake/2012_Guatemala_earthquake-event_description.json  \n",
            "  inflating: CrisisLexT26/2012_Guatemala_earthquake/2012_Guatemala_earthquake-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2012_Guatemala_earthquake/2012_Guatemala_earthquake-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2012_Guatemala_earthquake/README.md  \n",
            "  inflating: CrisisLexT26/2012_Italy_earthquakes/2012_Italy_earthquakes-event_description.json  \n",
            "  inflating: CrisisLexT26/2012_Italy_earthquakes/2012_Italy_earthquakes-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2012_Italy_earthquakes/2012_Italy_earthquakes-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2012_Italy_earthquakes/README.md  \n",
            "  inflating: CrisisLexT26/2012_Philipinnes_floods/2012_Philipinnes_floods-event_description.json  \n",
            "  inflating: CrisisLexT26/2012_Philipinnes_floods/2012_Philipinnes_floods-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2012_Philipinnes_floods/2012_Philipinnes_floods-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2012_Philipinnes_floods/README.md  \n",
            "  inflating: CrisisLexT26/2012_Typhoon_Pablo/2012_Typhoon_Pablo-event_description.json  \n",
            "  inflating: CrisisLexT26/2012_Typhoon_Pablo/2012_Typhoon_Pablo-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2012_Typhoon_Pablo/2012_Typhoon_Pablo-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2012_Typhoon_Pablo/README.md  \n",
            "  inflating: CrisisLexT26/2012_Venezuela_refinery/2012_Venezuela_refinery-event_description.json  \n",
            "  inflating: CrisisLexT26/2012_Venezuela_refinery/2012_Venezuela_refinery-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2012_Venezuela_refinery/2012_Venezuela_refinery-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2012_Venezuela_refinery/README.md  \n",
            "  inflating: CrisisLexT26/2013_Alberta_floods/2013_Alberta_floods-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Alberta_floods/2013_Alberta_floods-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Alberta_floods/2013_Alberta_floods-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Alberta_floods/README.md  \n",
            "  inflating: CrisisLexT26/2013_Australia_bushfire/2013_Australia_bushfire-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Australia_bushfire/2013_Australia_bushfire-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Australia_bushfire/2013_Australia_bushfire-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Australia_bushfire/README.md  \n",
            "  inflating: CrisisLexT26/2013_Bohol_earthquake/2013_Bohol_earthquake-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Bohol_earthquake/2013_Bohol_earthquake-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Bohol_earthquake/2013_Bohol_earthquake-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Bohol_earthquake/README.md  \n",
            "  inflating: CrisisLexT26/2013_Boston_bombings/2013_Boston_bombings-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Boston_bombings/2013_Boston_bombings-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Boston_bombings/2013_Boston_bombings-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Boston_bombings/README.md  \n",
            "  inflating: CrisisLexT26/2013_Brazil_nightclub_fire/2013_Brazil_nightclub_fire-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Brazil_nightclub_fire/2013_Brazil_nightclub_fire-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Brazil_nightclub_fire/2013_Brazil_nightclub_fire-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Brazil_nightclub_fire/README.md  \n",
            "  inflating: CrisisLexT26/2013_Colorado_floods/2013_Colorado_floods-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Colorado_floods/2013_Colorado_floods-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Colorado_floods/2013_Colorado_floods-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Colorado_floods/README.md  \n",
            "  inflating: CrisisLexT26/2013_Glasgow_helicopter_crash/2013_Glasgow_helicopter_crash-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Glasgow_helicopter_crash/2013_Glasgow_helicopter_crash-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Glasgow_helicopter_crash/2013_Glasgow_helicopter_crash-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Glasgow_helicopter_crash/README.md  \n",
            "  inflating: CrisisLexT26/2013_LA_airport_shootings/2013_LA_airport_shootings-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_LA_airport_shootings/2013_LA_airport_shootings-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_LA_airport_shootings/2013_LA_airport_shootings-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_LA_airport_shootings/README.md  \n",
            "  inflating: CrisisLexT26/2013_Lac_Megantic_train_crash/2013_Lac_Megantic_train_crash-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Lac_Megantic_train_crash/2013_Lac_Megantic_train_crash-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Lac_Megantic_train_crash/2013_Lac_Megantic_train_crash-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Lac_Megantic_train_crash/README.md  \n",
            "  inflating: CrisisLexT26/2013_Manila_floods/2013_Manila_floods-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Manila_floods/2013_Manila_floods-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Manila_floods/2013_Manila_floods-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Manila_floods/README.md  \n",
            "  inflating: CrisisLexT26/2013_NY_train_crash/2013_NY_train_crash-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_NY_train_crash/2013_NY_train_crash-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_NY_train_crash/2013_NY_train_crash-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_NY_train_crash/README.md  \n",
            "  inflating: CrisisLexT26/2013_Queensland_floods/2013_Queensland_floods-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Queensland_floods/2013_Queensland_floods-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Queensland_floods/2013_Queensland_floods-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Queensland_floods/README.md  \n",
            "  inflating: CrisisLexT26/2013_Russia_meteor/2013_Russia_meteor-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Russia_meteor/2013_Russia_meteor-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Russia_meteor/2013_Russia_meteor-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Russia_meteor/README.md  \n",
            "  inflating: CrisisLexT26/2013_Sardinia_floods/2013_Sardinia_floods-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Sardinia_floods/2013_Sardinia_floods-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Sardinia_floods/2013_Sardinia_floods-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Sardinia_floods/README.md  \n",
            "  inflating: CrisisLexT26/2013_Savar_building_collapse/2013_Savar_building_collapse-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Savar_building_collapse/2013_Savar_building_collapse-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Savar_building_collapse/2013_Savar_building_collapse-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Savar_building_collapse/README.md  \n",
            "  inflating: CrisisLexT26/2013_Singapore_haze/2013_Singapore_haze-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Singapore_haze/2013_Singapore_haze-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Singapore_haze/2013_Singapore_haze-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Singapore_haze/README.md  \n",
            "  inflating: CrisisLexT26/2013_Spain_train_crash/2013_Spain_train_crash-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Spain_train_crash/2013_Spain_train_crash-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Spain_train_crash/2013_Spain_train_crash-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Spain_train_crash/README.md  \n",
            "  inflating: CrisisLexT26/2013_Typhoon_Yolanda/2013_Typhoon_Yolanda-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_Typhoon_Yolanda/2013_Typhoon_Yolanda-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_Typhoon_Yolanda/2013_Typhoon_Yolanda-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_Typhoon_Yolanda/README.md  \n",
            "  inflating: CrisisLexT26/2013_West_Texas_explosion/2013_West_Texas_explosion-event_description.json  \n",
            "  inflating: CrisisLexT26/2013_West_Texas_explosion/2013_West_Texas_explosion-tweetids_entire_period.csv  \n",
            "  inflating: CrisisLexT26/2013_West_Texas_explosion/2013_West_Texas_explosion-tweets_labeled.csv  \n",
            "  inflating: CrisisLexT26/2013_West_Texas_explosion/README.md  \n",
            "  inflating: CrisisLexT26/README.md  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAG9B97vBPhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import sys\n",
        "from langdetect import detect\n",
        "import json\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iClO8R3ABTy5",
        "colab_type": "code",
        "outputId": "75716f1a-abd6-47f3-cd57-c20cbaf2c1dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
        "embed = hub.Module(module_url)\n",
        "text_placeholder = tf.placeholder(tf.string, shape=[None])\n",
        "embedding = embed(text_placeholder)\n",
        "test_strings = [\"OMG There is a huge typhoon in Miami. Save lives here: https://fdsjhfgsdeijg.com\", \"There is another report of a california fire.\",\n",
        "                \"Hey look at my cute dog\", \"#TheFamilyManTrailer *When the topper ignores me during the exam* Me after some fake humble try:\",\n",
        "               \"Now Post-Tropical (meaning technically no longer a hurricane) #Dorian making landfall in Canada this evening. Despite the name change, the system is still producing wind gusts up to 100mph! Hurricane Warnings in place along the southeast Canadian coast through the overnight.\"]\n",
        "test_vectors = []\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  test_vectors = session.run(embedding, feed_dict={text_placeholder: test_strings})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpbOHBCcBj4t",
        "colab_type": "code",
        "outputId": "91159f4a-a3ed-4e65-fabe-c945034770af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_pd = pd.read_csv('CrisisLexT26/2013_Spain_train_crash/2013_Spain_train_crash-tweets_labeled.csv')\n",
        "test_pd.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet ID</th>\n",
              "      <th>Tweet Text</th>\n",
              "      <th>Information Source</th>\n",
              "      <th>Information Type</th>\n",
              "      <th>Informativeness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>359949548937945091</td>\n",
              "      <td>España busca exportar su tren de alta velocida...</td>\n",
              "      <td>Not labeled</td>\n",
              "      <td>Not labeled</td>\n",
              "      <td>Not related</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>360118977848016896</td>\n",
              "      <td>RT @elmundoes: URGENTE: Descarrila un tren de ...</td>\n",
              "      <td>Media</td>\n",
              "      <td>Other Useful Information</td>\n",
              "      <td>Related and informative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>360120559088050176</td>\n",
              "      <td>RT @copecoruna: ÚLTIMA HORA: Descarrila un tre...</td>\n",
              "      <td>Media</td>\n",
              "      <td>Other Useful Information</td>\n",
              "      <td>Related and informative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>360120953373593600</td>\n",
              "      <td>Ha descarrilado un tren en santiago de Compostela</td>\n",
              "      <td>Media</td>\n",
              "      <td>Other Useful Information</td>\n",
              "      <td>Related and informative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>360121477636423683</td>\n",
              "      <td>RT @abc_es: #ACTUALIZACIÓN: Diez muertos tras ...</td>\n",
              "      <td>Media</td>\n",
              "      <td>Affected individuals</td>\n",
              "      <td>Related and informative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Tweet ID  ...          Informativeness\n",
              "0  359949548937945091  ...              Not related\n",
              "1  360118977848016896  ...  Related and informative\n",
              "2  360120559088050176  ...  Related and informative\n",
              "3  360120953373593600  ...  Related and informative\n",
              "4  360121477636423683  ...  Related and informative\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tv8oYKJBt2D",
        "colab_type": "code",
        "outputId": "5ad13e3f-6427-4843-8747-a028ad36cb16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(test_pd.keys())\n",
        "print(test_pd.groupby([' Informativeness']).groups.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Tweet ID', ' Tweet Text', ' Information Source', ' Information Type',\n",
            "       ' Informativeness'],\n",
            "      dtype='object')\n",
            "dict_keys(['Not applicable', 'Not related', 'Related - but not informative', 'Related and informative'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RunjEeofBv1M",
        "colab_type": "code",
        "outputId": "d0fce573-b968-47ef-c02f-237d284559aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_pd['lang'] = test_pd[' Tweet Text'].apply(detect)\n",
        "test_pd.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet ID</th>\n",
              "      <th>Tweet Text</th>\n",
              "      <th>Information Source</th>\n",
              "      <th>Information Type</th>\n",
              "      <th>Informativeness</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>359949548937945091</td>\n",
              "      <td>España busca exportar su tren de alta velocida...</td>\n",
              "      <td>Not labeled</td>\n",
              "      <td>Not labeled</td>\n",
              "      <td>Not related</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>360118977848016896</td>\n",
              "      <td>RT @elmundoes: URGENTE: Descarrila un tren de ...</td>\n",
              "      <td>Media</td>\n",
              "      <td>Other Useful Information</td>\n",
              "      <td>Related and informative</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>360120559088050176</td>\n",
              "      <td>RT @copecoruna: ÚLTIMA HORA: Descarrila un tre...</td>\n",
              "      <td>Media</td>\n",
              "      <td>Other Useful Information</td>\n",
              "      <td>Related and informative</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>360120953373593600</td>\n",
              "      <td>Ha descarrilado un tren en santiago de Compostela</td>\n",
              "      <td>Media</td>\n",
              "      <td>Other Useful Information</td>\n",
              "      <td>Related and informative</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>360121477636423683</td>\n",
              "      <td>RT @abc_es: #ACTUALIZACIÓN: Diez muertos tras ...</td>\n",
              "      <td>Media</td>\n",
              "      <td>Affected individuals</td>\n",
              "      <td>Related and informative</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Tweet ID  ... lang\n",
              "0  359949548937945091  ...   es\n",
              "1  360118977848016896  ...   es\n",
              "2  360120559088050176  ...   es\n",
              "3  360120953373593600  ...   es\n",
              "4  360121477636423683  ...   es\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvS1erHHByfK",
        "colab_type": "code",
        "outputId": "e5fdb9b0-4b3c-46e9-e068-63d7319293a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_pd[test_pd['lang'] == 'en'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet ID</th>\n",
              "      <th>Tweet Text</th>\n",
              "      <th>Information Source</th>\n",
              "      <th>Information Type</th>\n",
              "      <th>Informativeness</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>360122056471355393</td>\n",
              "      <td>RT @NewsBreaker: BREAKING: Casualties reported...</td>\n",
              "      <td>Media</td>\n",
              "      <td>Other Useful Information</td>\n",
              "      <td>Related and informative</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>360127072837963776</td>\n",
              "      <td>@SteveInMadrid: BREAKING UPDATE 5 Exclusive Pi...</td>\n",
              "      <td>Media</td>\n",
              "      <td>Other Useful Information</td>\n",
              "      <td>Related and informative</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>360127764927479808</td>\n",
              "      <td>Train Crash In Spain: Several Deaths Reported ...</td>\n",
              "      <td>Media</td>\n",
              "      <td>Other Useful Information</td>\n",
              "      <td>Related and informative</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>360129643967299584</td>\n",
              "      <td>Spain high-speed train crashes near Santiago d...</td>\n",
              "      <td>Media</td>\n",
              "      <td>Other Useful Information</td>\n",
              "      <td>Related and informative</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>360134064734347264</td>\n",
              "      <td>RT @NewsBreaker: BREAKING PIC: 4 dead after tr...</td>\n",
              "      <td>Media</td>\n",
              "      <td>Affected individuals</td>\n",
              "      <td>Related and informative</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Tweet ID  ... lang\n",
              "6   360122056471355393  ...   en\n",
              "15  360127072837963776  ...   en\n",
              "18  360127764927479808  ...   en\n",
              "24  360129643967299584  ...   en\n",
              "34  360134064734347264  ...   en\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kbVcBqxB2UT",
        "colab_type": "code",
        "outputId": "d906674e-be4a-4c34-8400-9f7e9faee771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "ignore_types = ['Collapse', 'Meteorite', 'Haze']\n",
        "type_maps = {'Floods': 'Floods',\n",
        "            'Typhoon': 'Typhoon',\n",
        "            'Shootings': 'Terrorism', 'Bombings': 'Terrorism',\n",
        "            'Wildfire': 'Fire', 'Fire': 'Fire',\n",
        "            'Derailment': 'Crash', 'Crash': 'Crash',\n",
        "            'Explosion': 'Explosion',\n",
        "            'Earthquake': 'Earthquake'}\n",
        "all_disasters = [os.path.join('CrisisLexT26', f) for f in os.listdir('CrisisLexT26')]\n",
        "# print(all_disasters)\n",
        "type_dict = dict()\n",
        "category_dict = dict()\n",
        "\n",
        "tweets = []\n",
        "tweets_type = []\n",
        "related = []\n",
        "\n",
        "\n",
        "for all_d in tqdm(all_disasters):\n",
        "  try:\n",
        "    json_file = [os.path.join(all_d, f) for f in os.listdir(all_d) if f.endswith(\"json\")][0]\n",
        "    csv_file = [os.path.join(all_d, f) for f in os.listdir(all_d) if f.endswith(\"-tweets_labeled.csv\")][0]\n",
        "    json_dict = json.load(open(json_file, \"r\"))\n",
        "    this_type = json_dict['categorization']['type']\n",
        "    if this_type in ignore_types:\n",
        "      continue\n",
        "    this_new_type = type_maps[this_type]\n",
        "    this_df = pd.read_csv(csv_file)\n",
        "    print(len(this_df))\n",
        "    this_df['lang'] = this_df[' Tweet Text'].apply(detect)\n",
        "    this_df = this_df[this_df['lang'] == 'en']\n",
        "    this_tweet_list = this_df[' Tweet Text'].tolist()\n",
        "    this_df['related'] = this_df[' Informativeness'].apply(lambda x: int(x in ['Related - but not informative', 'Related and informative']))\n",
        "    this_related_list = this_df['related'].tolist()\n",
        "    tweets.extend(this_tweet_list)\n",
        "    related.extend(this_related_list)\n",
        "    tweets_type.extend([this_new_type for _ in this_related_list])\n",
        "    # type_dict[json_dict['categorization']['type']] = type_dict.get(json_dict['categorization']['type'], 0) + 1\n",
        "    # category_dict[json_dict['categorization']['category']] = category_dict.get(json_dict['categorization']['category'], 0) + 1\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    continue"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/28 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  4%|▎         | 1/28 [00:06<03:02,  6.75s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  7%|▋         | 2/28 [00:13<02:51,  6.61s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 11%|█         | 3/28 [00:18<02:33,  6.12s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 14%|█▍        | 4/28 [00:25<02:34,  6.43s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 18%|█▊        | 5/28 [00:30<02:18,  6.04s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 21%|██▏       | 6/28 [00:35<02:07,  5.79s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 25%|██▌       | 7/28 [00:45<02:25,  6.91s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1199\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 29%|██▊       | 8/28 [00:50<02:11,  6.57s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 32%|███▏      | 9/28 [00:57<02:03,  6.48s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 36%|███▌      | 10/28 [01:03<01:53,  6.31s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 39%|███▉      | 11/28 [01:08<01:40,  5.94s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 43%|████▎     | 12/28 [01:14<01:37,  6.12s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 46%|████▋     | 13/28 [01:20<01:32,  6.15s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 14/28 [01:25<01:19,  5.70s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 54%|█████▎    | 15/28 [01:33<01:22,  6.38s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 61%|██████    | 17/28 [01:40<01:01,  5.58s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 64%|██████▍   | 18/28 [01:46<00:56,  5.68s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 68%|██████▊   | 19/28 [01:53<00:54,  6.09s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Errno 20] Not a directory: 'CrisisLexT26/README.md'\n",
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 82%|████████▏ | 23/28 [01:59<00:23,  4.69s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Errno 20] Not a directory: 'CrisisLexT26/.DS_Store'\n",
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 89%|████████▉ | 25/28 [02:05<00:12,  4.21s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 93%|█████████▎| 26/28 [02:19<00:13,  6.97s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 96%|█████████▋| 27/28 [02:24<00:06,  6.61s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 28/28 [02:30<00:00,  6.33s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMObzYJbB4cY",
        "colab_type": "code",
        "outputId": "1d7b63e6-ff31-4e35-f451-b2356e5bdaea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "over_df = pd.DataFrame({'Tweet': tweets, 'Type': tweets_type, 'Related': related})\n",
        "print(len(tweets))\n",
        "over_df.groupby('Type').count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Related</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Type</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Crash</th>\n",
              "      <td>2974</td>\n",
              "      <td>2974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Earthquake</th>\n",
              "      <td>1922</td>\n",
              "      <td>1922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Explosion</th>\n",
              "      <td>1018</td>\n",
              "      <td>1018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fire</th>\n",
              "      <td>2738</td>\n",
              "      <td>2738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Floods</th>\n",
              "      <td>4803</td>\n",
              "      <td>4803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Terrorism</th>\n",
              "      <td>1913</td>\n",
              "      <td>1913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Typhoon</th>\n",
              "      <td>1752</td>\n",
              "      <td>1752</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Tweet  Related\n",
              "Type                      \n",
              "Crash        2974     2974\n",
              "Earthquake   1922     1922\n",
              "Explosion    1018     1018\n",
              "Fire         2738     2738\n",
              "Floods       4803     4803\n",
              "Terrorism    1913     1913\n",
              "Typhoon      1752     1752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzNAC8KcB_aw",
        "colab_type": "code",
        "outputId": "81702b4e-e896-4d6b-f15c-e9a05db555b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "over_df.groupby('Related').count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Related</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1703</td>\n",
              "      <td>1703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15417</td>\n",
              "      <td>15417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Tweet   Type\n",
              "Related              \n",
              "0         1703   1703\n",
              "1        15417  15417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flcAKBigCBKP",
        "colab_type": "code",
        "outputId": "62083498-c903-4d2a-eb2c-7958debc4616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  over_df['Vectors'] = session.run(embed(over_df['Tweet'].tolist())).tolist()\n",
        "over_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "      <th>Related</th>\n",
              "      <th>Vectors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @Jack4Ward: Get in on the fun every Thursda...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.018871961161494255, 0.05218875780701637, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Welcome to our newest STUDENTathlete- Reagan B...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.024413956329226494, 0.035585999488830566, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Denver Post: #Colorado governor signs bill cre...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.04952438175678253, -0.04628261923789978, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pretty sure I'm going to live in Manitou Sprin...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.0073580024763941765, 0.036944229155778885, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Flying over the beautiful snow capped #mountai...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.02702946774661541, -0.009432152844965458, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>It isn't a beach but just as great #colorado #...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.045321449637413025, 0.06808455288410187, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>#colorado. Told you its #amazing http://t.co/6...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.031008010730147362, -0.008062882348895073, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RT @xRedRoverx: #Colorado #news #crime 3 bodie...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.029940232634544373, -0.07236875593662262, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>checkmate payday loans colorado springs http:/...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.06465433537960052, 0.045164112001657486, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Free #HTC #Wildfire S, 250 minutes, 5,000 text...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.040880363434553146, 0.021573971956968307, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  ...                                            Vectors\n",
              "0  RT @Jack4Ward: Get in on the fun every Thursda...  ...  [0.018871961161494255, 0.05218875780701637, -0...\n",
              "1  Welcome to our newest STUDENTathlete- Reagan B...  ...  [0.024413956329226494, 0.035585999488830566, -...\n",
              "2  Denver Post: #Colorado governor signs bill cre...  ...  [0.04952438175678253, -0.04628261923789978, -0...\n",
              "3  Pretty sure I'm going to live in Manitou Sprin...  ...  [0.0073580024763941765, 0.036944229155778885, ...\n",
              "4  Flying over the beautiful snow capped #mountai...  ...  [0.02702946774661541, -0.009432152844965458, -...\n",
              "5  It isn't a beach but just as great #colorado #...  ...  [-0.045321449637413025, 0.06808455288410187, -...\n",
              "6  #colorado. Told you its #amazing http://t.co/6...  ...  [0.031008010730147362, -0.008062882348895073, ...\n",
              "7  RT @xRedRoverx: #Colorado #news #crime 3 bodie...  ...  [0.029940232634544373, -0.07236875593662262, -...\n",
              "8  checkmate payday loans colorado springs http:/...  ...  [0.06465433537960052, 0.045164112001657486, -0...\n",
              "9  Free #HTC #Wildfire S, 250 minutes, 5,000 text...  ...  [0.040880363434553146, 0.021573971956968307, -...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9G4bVVXCB0f",
        "colab_type": "code",
        "outputId": "38f87dd6-5e04-47c8-a4e7-a4539c84c82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "idx2text = list(over_df.groupby(['Type']).groups.keys()) + ['None']\n",
        "text2idx = dict((x.strip(), i) for (i, x) in enumerate(idx2text))\n",
        "print(idx2text)\n",
        "print(text2idx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Crash', 'Earthquake', 'Explosion', 'Fire', 'Floods', 'Terrorism', 'Typhoon', 'None']\n",
            "{'Crash': 0, 'Earthquake': 1, 'Explosion': 2, 'Fire': 3, 'Floods': 4, 'Terrorism': 5, 'Typhoon': 6, 'None': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b84_OocjEvVf",
        "colab_type": "code",
        "outputId": "d0179405-43d8-4047-9660-9a97d9b1d1d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "over_df['Type_INT'] = over_df['Type'].apply(lambda x: text2idx[x])\n",
        "over_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "      <th>Related</th>\n",
              "      <th>Vectors</th>\n",
              "      <th>Type_INT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @Jack4Ward: Get in on the fun every Thursda...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.018871961161494255, 0.05218875780701637, -0...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Welcome to our newest STUDENTathlete- Reagan B...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.024413956329226494, 0.035585999488830566, -...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Denver Post: #Colorado governor signs bill cre...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.04952438175678253, -0.04628261923789978, -0...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pretty sure I'm going to live in Manitou Sprin...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.0073580024763941765, 0.036944229155778885, ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Flying over the beautiful snow capped #mountai...</td>\n",
              "      <td>Fire</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.02702946774661541, -0.009432152844965458, -...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  ... Type_INT\n",
              "0  RT @Jack4Ward: Get in on the fun every Thursda...  ...        3\n",
              "1  Welcome to our newest STUDENTathlete- Reagan B...  ...        3\n",
              "2  Denver Post: #Colorado governor signs bill cre...  ...        3\n",
              "3  Pretty sure I'm going to live in Manitou Sprin...  ...        3\n",
              "4  Flying over the beautiful snow capped #mountai...  ...        3\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMnRzb7qEw_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "over_df.to_csv('vectored.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5XS36yWEzuq",
        "colab_type": "code",
        "outputId": "37d72b2d-04b7-4007-f3bd-5c0fc1de7aab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "zipped_ds = list(zip(over_df['Related'].tolist(), over_df['Vectors'].tolist(), over_df['Type_INT'].tolist()))\n",
        "new_zipped_ds = []\n",
        "posw = np.zeros([8])\n",
        "for r, vc, ti in zipped_ds:\n",
        "  if r == 1:\n",
        "    posw[ti] += 1\n",
        "    new_zipped_ds.append((1, vc, ti))\n",
        "  else:\n",
        "    posw[7] += 1\n",
        "    new_zipped_ds.append((0, vc, 7))\n",
        "zipped_ds = new_zipped_ds\n",
        "import random\n",
        "random.shuffle(zipped_ds)\n",
        "train_count = int(0.9*len(zipped_ds))\n",
        "train_set = zipped_ds[:train_count]\n",
        "test_set = zipped_ds[train_count:]\n",
        "\n",
        "def gelu_fast(_x):\n",
        "  return 0.5 * _x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (_x + 0.044715 * tf.pow(_x, 3))))\n",
        "print(len(train_set))\n",
        "print(len(test_set))\n",
        "print(posw)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15408\n",
            "1712\n",
            "[2776. 1596.  946. 2267. 4359. 1816. 1657. 1703.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkpdpa4CE1iX",
        "colab_type": "code",
        "outputId": "dcf1f9a5-9d6b-4e07-dd33-9fd532a214bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Session() as session:\n",
        "  batch_size = 16\n",
        "  y_placeholder = tf.placeholder(tf.int32, shape=[batch_size])\n",
        "  type_placeholder = tf.placeholder(tf.int32, shape=[batch_size])\n",
        "  tp_onehot = tf.one_hot(type_placeholder, 8, dtype=tf.float32)\n",
        "  vector_placeholder = tf.placeholder(tf.float32, shape=[batch_size, 512])\n",
        "  dropout_val = tf.placeholder(tf.float32, shape=[])\n",
        "#   with tf.variable_scope(\"wtf\", reuse=tf.AUTO_REUSE) as scope:\n",
        "#     trainable_embeddings = tf.get_variable(\"trainable_embedding\", shape=[7, 32],\n",
        "#           initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float32)\n",
        "\n",
        "#     x = tf.nn.embedding_lookup(trainable_embeddings, type_placeholder) # (batch_size, 1, 32)\n",
        "#   print(x)\n",
        "  # x = tf.reshape(x, [batch_size, 32])\n",
        "  # x = tf.concat([vector_placeholder, x], axis=-1)\n",
        "  x = vector_placeholder\n",
        "\n",
        "  x = tf.layers.dense(x, 256, activation=gelu_fast, trainable=True, name=\"l1\",\n",
        "      reuse=tf.AUTO_REUSE)\n",
        "  x = tf.layers.dense(x, 64, activation=gelu_fast, trainable=True, name=\"l2\",\n",
        "      reuse=tf.AUTO_REUSE)\n",
        "  x = tf.nn.dropout(x, dropout_val)\n",
        "  print(x)\n",
        "  logits = tf.layers.dense(x, 8, activation=None, trainable=True, name=\"fc\",\n",
        "      reuse=tf.AUTO_REUSE)\n",
        "  probs = tf.nn.softmax(logits, axis=-1)\n",
        "  print(logits)\n",
        "\n",
        "  print(y_placeholder)\n",
        "  cost = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(labels=tp_onehot, logits=logits, pos_weight=17121/posw)) # tf.nn.sparse_softmax_cross_entropy_with_logits(labels=type_placeholder, logits=logits))\n",
        "  predictionsss = tf.argmax(logits, axis=-1)\n",
        "  conf_matrix = tf.math.confusion_matrix(type_placeholder, predictionsss, num_classes=8)\n",
        "  acc, acc_op = tf.metrics.accuracy(type_placeholder,\n",
        "                                    predictionsss)\n",
        "  \n",
        "  cel = tf.summary.scalar('cross-entropy-loss', cost)\n",
        "  acc_s = tf.summary.scalar('avg_acc', acc)\n",
        "  summary = tf.summary.merge([cel, acc_s])\n",
        "  \n",
        "  print(tf.trainable_variables())\n",
        "\n",
        "  optimizer = tf.train.AdamOptimizer(0.001)\n",
        "  gradsvars = optimizer.compute_gradients(cost, var_list=tf.trainable_variables())\n",
        "  grads, _ = tf.clip_by_global_norm([g for g, v in gradsvars], 50)\n",
        "  optimize_fn = optimizer.apply_gradients(zip(grads, tf.trainable_variables()))\n",
        "  \n",
        "  running_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES)\n",
        "  running_vars_initializer = tf.variables_initializer(var_list=running_vars)\n",
        "  \n",
        "  saver = tf.train.Saver(max_to_keep=5)\n",
        "\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  \n",
        "  for ep in range(7):\n",
        "    train_count = len(train_set) // batch_size\n",
        "    test_count = len(test_set) // batch_size\n",
        "    session.run(running_vars_initializer)\n",
        "    total_cost = 0\n",
        "    total_conf_matrix = np.zeros([8, 8], dtype=np.int32)\n",
        "    for i in range(train_count):\n",
        "      xxx = train_set[i*batch_size: (i+1)*batch_size]\n",
        "      y_output, input_vectors, input_type = zip(*xxx)\n",
        "      c, _, _, cf = session.run([cost, optimize_fn, acc_op, conf_matrix],\n",
        "                            feed_dict={y_placeholder: y_output,\n",
        "                                       vector_placeholder: input_vectors,\n",
        "                                       type_placeholder: input_type,\n",
        "                                       dropout_val: 0.5})\n",
        "      total_conf_matrix += cf\n",
        "      total_cost += c\n",
        "      # if tc % (train_count//2) == 0:\n",
        "      #   print(c, session.run(acc))\n",
        "    print(\"---TRAIN---\")\n",
        "    print(total_cost/train_count, session.run(acc))\n",
        "    saver.save(session, \"DisasterNet\", global_step=ep)\n",
        "    print(total_conf_matrix)\n",
        "    \n",
        "    session.run(running_vars_initializer)\n",
        "    total_cost = 0\n",
        "    total_conf_matrix = np.zeros([8, 8], dtype=np.int32)\n",
        "    for i in range(test_count):\n",
        "      xxx = test_set[i*batch_size: (i+1)*batch_size]\n",
        "      y_output, input_vectors, input_type = zip(*xxx)\n",
        "      c, _, cf = session.run([cost, acc_op, conf_matrix],\n",
        "                            feed_dict={y_placeholder: y_output,\n",
        "                                       vector_placeholder: input_vectors,\n",
        "                                       type_placeholder: input_type,\n",
        "                                       dropout_val: 1.0})\n",
        "      total_conf_matrix += cf\n",
        "      total_cost += c\n",
        "      # if tc % (test_count//2) == 0:\n",
        "      #   print(c, session.run(acc))\n",
        "    print(\"---TEST---\")\n",
        "    print(total_cost/test_count, session.run(acc))\n",
        "    print(total_conf_matrix)\n",
        "\n",
        "    for tv in test_vectors:\n",
        "      ppp = session.run(probs, feed_dict={vector_placeholder: [tv]*batch_size, dropout_val: 1.0})[0]\n",
        "      pp_val = np.argmax(ppp)\n",
        "      print(idx2text[pp_val], ppp[pp_val])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"dropout/mul_1:0\", shape=(16, 64), dtype=float32)\n",
            "Tensor(\"fc/BiasAdd:0\", shape=(16, 8), dtype=float32)\n",
            "Tensor(\"Placeholder:0\", shape=(16,), dtype=int32)\n",
            "[<tf.Variable 'l1/kernel:0' shape=(512, 256) dtype=float32_ref>, <tf.Variable 'l1/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'l2/kernel:0' shape=(256, 64) dtype=float32_ref>, <tf.Variable 'l2/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc/kernel:0' shape=(64, 8) dtype=float32_ref>, <tf.Variable 'fc/bias:0' shape=(8,) dtype=float32_ref>]\n",
            "---TRAIN---\n",
            "0.6657819662200575 0.6725727\n",
            "[[2142   15   54   32  104   55   48   38]\n",
            " [  10 1065   63   13   55   20  131   89]\n",
            " [  13   23  571   62   43   78   19   43]\n",
            " [  72   30  162 1261  311   63   37   96]\n",
            " [ 136  103  171  240 2502   68  462  221]\n",
            " [  76   16   96   23   23 1316   27   52]\n",
            " [  24  139   39   33  276   25  908   61]\n",
            " [ 108  193   68  146  201  122  117  598]]\n",
            "---TEST---\n",
            "0.4774032938424672 0.75\n",
            "[[258   2   4   6  10   2   3   3]\n",
            " [  0 127   2   1   5   1   8   6]\n",
            " [  0   5  64   3   3  12   3   4]\n",
            " [  6   2   1 178  30   5   6   7]\n",
            " [ 14   6   8  18 323   5  55  27]\n",
            " [  2   2  10   0   2 157   5   9]\n",
            " [  0   4   4   3  10   1 126   4]\n",
            " [  8  26   8  14  17  16  10  51]]\n",
            "Typhoon 0.7124642\n",
            "Fire 0.8736205\n",
            "None 0.96904546\n",
            "None 0.4816244\n",
            "Floods 0.7846131\n",
            "---TRAIN---\n",
            "0.48786112127645737 0.75629544\n",
            "[[2216   11   37   29   78   42   33   42]\n",
            " [   7 1201   21   19   37   10   85   66]\n",
            " [  16   20  628   36   34   60   10   48]\n",
            " [  31   24   62 1515  229   36   33  102]\n",
            " [  88   85   65  201 2769   45  387  263]\n",
            " [  41    8   59   17   21 1412   23   48]\n",
            " [  17   70   17   35  191   22 1089   64]\n",
            " [  85  150   56  109  173   88   69  823]]\n",
            "---TEST---\n",
            "0.4399430453777313 0.7704439\n",
            "[[256   1   5   5  11   2   3   5]\n",
            " [  0 129   2   1   6   0   4   8]\n",
            " [  0   4  69   2   2  12   1   4]\n",
            " [  5   2   3 181  27   4   6   7]\n",
            " [ 13   6   9  16 341   4  36  31]\n",
            " [  2   1  12   0   1 157   5   9]\n",
            " [  0   8   3   3  11   0 121   6]\n",
            " [  8  26   5  12  16  10   8  65]]\n",
            "Typhoon 0.7798054\n",
            "Fire 0.9597246\n",
            "None 0.9930033\n",
            "None 0.59487474\n",
            "Floods 0.83888495\n",
            "---TRAIN---\n",
            "0.4548857693298336 0.769081\n",
            "[[2203   10   33   25   96   37   36   48]\n",
            " [   7 1199   20   18   42   10   75   75]\n",
            " [  12   21  651   31   35   50    8   44]\n",
            " [  28   20   35 1535  242   40   36   96]\n",
            " [  75   61   57  200 2836   66  341  267]\n",
            " [  29    8   58   20   24 1429   17   44]\n",
            " [   9   51   19   24  189   29 1116   68]\n",
            " [  78  127   64   96  166   82   59  881]]\n",
            "---TEST---\n",
            "0.4297942487157394 0.77278036\n",
            "[[257   0   5   4  10   2   4   6]\n",
            " [  0 128   2   1   6   1   5   7]\n",
            " [  1   4  70   3   1  12   1   2]\n",
            " [  5   2   2 187  23   5   6   5]\n",
            " [ 14   8   6  23 335   4  43  23]\n",
            " [  2   2  10   0   2 160   5   6]\n",
            " [  0   5   3   3   8   0 127   6]\n",
            " [  8  27   4  13  19  11   9  59]]\n",
            "Typhoon 0.9070559\n",
            "Fire 0.9778081\n",
            "None 0.99227\n",
            "None 0.5184935\n",
            "Floods 0.79491544\n",
            "---TRAIN---\n",
            "0.4301274229123461 0.7804387\n",
            "[[2200    9   33   25  105   50   24   42]\n",
            " [   6 1220   15   16   36   14   74   65]\n",
            " [   8   15  657   32   36   61    7   36]\n",
            " [  25   17   33 1565  230   37   37   88]\n",
            " [  65   64   54  205 2892   46  323  254]\n",
            " [  26   17   41   12   24 1439   21   49]\n",
            " [  17   65   16   32  188   22 1107   58]\n",
            " [  75  100   53   98  153   76   53  945]]\n",
            "---TEST---\n",
            "0.4135511787695305 0.77978975\n",
            "[[254   0   5   3  14   2   4   6]\n",
            " [  0 126   2   1   6   0   6   9]\n",
            " [  0   3  70   3   3  11   1   3]\n",
            " [  2   2   2 188  27   4   4   6]\n",
            " [ 11   7   8  21 347   3  34  25]\n",
            " [  2   2  11   1   2 158   4   7]\n",
            " [  0   3   3   3  14   1 122   6]\n",
            " [  6  23   4  12  19  10   6  70]]\n",
            "Typhoon 0.93075186\n",
            "Fire 0.9745292\n",
            "None 0.99427927\n",
            "None 0.61395234\n",
            "Floods 0.8552233\n",
            "---TRAIN---\n",
            "0.4120739199228871 0.792121\n",
            "[[2234    8   30   22   90   34   32   38]\n",
            " [   7 1224   17   10   50   15   62   61]\n",
            " [   9   18  669   31   37   46    7   35]\n",
            " [  23   15   36 1571  235   36   28   88]\n",
            " [  71   56   53  202 2960   41  286  234]\n",
            " [  27   12   55   19   28 1429   17   42]\n",
            " [  12   47   13   29  202   21 1125   56]\n",
            " [  67  105   49   82  143   67   47  993]]\n",
            "---TEST---\n",
            "0.4109347349850931 0.7838785\n",
            "[[254   0   4   4  13   3   3   7]\n",
            " [  0 127   2   1   6   0   5   9]\n",
            " [  0   3  68   3   3  13   1   3]\n",
            " [  2   2   2 185  29   5   2   8]\n",
            " [ 11   6   5  22 353   3  31  25]\n",
            " [  1   3   7   1   1 161   5   8]\n",
            " [  0   7   3   3  14   1 118   6]\n",
            " [  5  22   3  11  19   9   5  76]]\n",
            "Typhoon 0.9545919\n",
            "Fire 0.99154145\n",
            "None 0.98927444\n",
            "None 0.66156244\n",
            "Floods 0.86063063\n",
            "---TRAIN---\n",
            "0.3922023280511145 0.7977674\n",
            "[[2234    8   32   25   93   28   25   43]\n",
            " [   2 1236   18   11   42    9   60   68]\n",
            " [   7   16  682   33   31   48    6   29]\n",
            " [  21    7   34 1596  237   34   22   81]\n",
            " [  58   59   55  184 2973   41  289  244]\n",
            " [  22   10   51   15   29 1447   16   39]\n",
            " [  13   48   17   21  197   20 1122   67]\n",
            " [  70   91   48   89  143   63   47 1002]]\n",
            "---TEST---\n",
            "0.40608925616072716 0.7885514\n",
            "[[255   0   5   4  11   4   2   7]\n",
            " [  0 128   3   1   6   0   4   8]\n",
            " [  0   4  70   3   2  11   1   3]\n",
            " [  3   2   2 184  26   4   6   8]\n",
            " [ 11   5   4  24 354   3  32  23]\n",
            " [  2   2   9   1   2 161   4   6]\n",
            " [  0   6   4   2  11   1 123   5]\n",
            " [  5  19   3  12  22  10   4  75]]\n",
            "Typhoon 0.97102475\n",
            "Fire 0.9955537\n",
            "None 0.9933581\n",
            "None 0.8505844\n",
            "Floods 0.8909186\n",
            "---TRAIN---\n",
            "0.3779714234088193 0.8071781\n",
            "[[2242    5   29   21   91   38   30   32]\n",
            " [   4 1247   19    9   44    9   54   60]\n",
            " [  11   19  690   28   33   47    2   22]\n",
            " [  27   14   29 1602  213   34   30   83]\n",
            " [  57   61   42  191 3031   37  265  219]\n",
            " [  22   12   51   12   21 1452   23   36]\n",
            " [  10   46   17   26  198   21 1138   49]\n",
            " [  63   86   45   82  138   60   44 1035]]\n",
            "---TEST---\n",
            "0.4094294824193571 0.79497665\n",
            "[[254   1   4   2  16   3   2   6]\n",
            " [  0 129   3   1   5   0   4   8]\n",
            " [  0   3  72   3   3   9   1   3]\n",
            " [  3   2   2 186  28   3   5   6]\n",
            " [ 11   7   2  20 368   2  28  18]\n",
            " [  2   1  10   1   2 159   6   6]\n",
            " [  1   6   3   2  15   1 119   5]\n",
            " [  6  18   1  14  23  10   4  74]]\n",
            "Typhoon 0.96288824\n",
            "Fire 0.99054575\n",
            "None 0.97452796\n",
            "None 0.7694893\n",
            "Floods 0.82908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U7U2Y4DJNqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}